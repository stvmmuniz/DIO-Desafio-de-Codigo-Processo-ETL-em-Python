{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R-ILsH4Rz55k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä Desafio de C√≥digo ‚Äì Pipeline ETL em Python\n",
        "\n",
        "Este projeto tem como objetivo demonstrar, de forma pr√°tica, a aplica√ß√£o dos conceitos e boas pr√°ticas de **ETL (Extract, Transform, Load)** utilizando Python. O pipeline foi desenvolvido a partir de dados p√∫blicos do **Portal da Transpar√™ncia**, preparando o dataset final para an√°lise no **Power BI**.\n",
        "\n",
        "A solu√ß√£o foi estruturada de maneira modular e organizada, facilitando a leitura, manuten√ß√£o e reaproveitamento do c√≥digo, al√©m de evidenciar a capacidade t√©cnica aplicada na resolu√ß√£o do desafio."
      ],
      "metadata": {
        "id": "btYKpkCGz7-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öôÔ∏è Etapa 0 ‚Äì Configura√ß√£o do Ambiente\n",
        "\n",
        "Nesta etapa inicial, o ambiente √© preparado para garantir organiza√ß√£o e reprodutibilidade do processo:\n",
        "\n",
        "Importa√ß√£o de bibliotecas padr√£o do Python (`os`, `zipfile`, `glob`, `unicodedata`) e bibliotecas externas amplamente utilizadas em projetos de dados (`requests` e `pandas`);\n",
        "\n",
        "Defini√ß√£o de diret√≥rios separados para **dados brutos** (`data_raw`) e **dados processados** (`data_processed`), seguindo boas pr√°ticas de organiza√ß√£o;\n",
        "\n",
        "Cria√ß√£o autom√°tica dessas pastas, evitando erros em execu√ß√µes futuras.\n",
        "\n",
        "Essa estrutura facilita tanto o entendimento do fluxo quanto a escalabilidade do projeto."
      ],
      "metadata": {
        "id": "BmEq--qH0MK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ETAPA 0 ‚Äì CONFIGURA√á√ÉO DO AMBIENTE\n",
        "# ============================================================\n",
        "\n",
        "# Bibliotecas padr√£o\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "import unicodedata\n",
        "\n",
        "# Bibliotecas externas\n",
        "import requests\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "_Yueg_0a0CJ4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì• Etapa 1 ‚Äì Extra√ß√£o dos Dados (Extract)\n",
        "\n",
        "A etapa de extra√ß√£o √© respons√°vel por obter os dados diretamente da fonte oficial:\n",
        "\n",
        "* **Download automatizado** do arquivo ZIP a partir do Portal da Transpar√™ncia, utilizando requisi√ß√µes HTTP com tratamento de erros;\n",
        "\n",
        "* **Armazenamento do arquivo bruto localmente**, garantindo rastreabilidade dos dados originais;\n",
        "\n",
        "* **Extra√ß√£o controlada do conte√∫do do ZIP**, evitando duplicidades;\n",
        "\n",
        "* **Identifica√ß√£o autom√°tica do arquivo CSV** para processamento.\n",
        "\n",
        "Essa abordagem garante **confiabilidade** na origem dos dados e reduz depend√™ncias manuais.\n"
      ],
      "metadata": {
        "id": "ZHyilwz-0f7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ETAPA 1 ‚Äì EXTRA√á√ÉO DOS DADOS\n",
        "# ============================================================\n",
        "\n",
        "URL = \"https://portaldatransparencia.gov.br/download-de-dados/despesas-favorecidos/202511\"\n",
        "\n",
        "try:\n",
        "    BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "except NameError:\n",
        "    BASE_DIR = os.getcwd()\n",
        "\n",
        "RAW_DIR = os.path.join(BASE_DIR, \"data_raw\")\n",
        "PROCESSED_DIR = os.path.join(BASE_DIR, \"data_processed\")\n",
        "\n",
        "os.makedirs(RAW_DIR, exist_ok=True)\n",
        "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
        "\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "response = requests.get(URL, headers=headers)\n",
        "\n",
        "if response.status_code != 200:\n",
        "    raise Exception(f\"Erro no download | Status: {response.status_code}\")\n",
        "\n",
        "zip_path = os.path.join(RAW_DIR, \"despesas_favorecidos_202511.zip\")\n",
        "\n",
        "with open(zip_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(\"üì¶ ZIP baixado com sucesso!\")\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    for member in zip_ref.namelist():\n",
        "        target_path = os.path.join(RAW_DIR, member)\n",
        "        if os.path.exists(target_path):\n",
        "            os.remove(target_path)\n",
        "        zip_ref.extract(member, RAW_DIR)\n",
        "\n",
        "print(\"üìÇ ZIP extra√≠do com sucesso!\")\n",
        "\n",
        "csv_files = glob.glob(os.path.join(RAW_DIR, \"*.csv\"))\n",
        "\n",
        "if not csv_files:\n",
        "    raise Exception(\"Nenhum arquivo CSV encontrado ap√≥s extra√ß√£o do ZIP.\")\n",
        "\n",
        "raw_file = csv_files[0]\n",
        "print(f\"üìÑ CSV identificado: {os.path.basename(raw_file)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0DSqa2G0SOH",
        "outputId": "3c2fa0b3-e9da-48c4-aba9-6418b7375dbb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ ZIP baixado com sucesso!\n",
            "üìÇ ZIP extra√≠do com sucesso!\n",
            "üìÑ CSV identificado: 202511_RecebimentosRecursosPorFavorecido.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîÑ Etapa 2 ‚Äì Transforma√ß√£o dos Dados (Transform)\n",
        "\n",
        "Esta √© a etapa central do processo, onde os dados brutos s√£o tratados e padronizados para uso anal√≠tico.\n",
        "\n",
        "## 2.1 Padroniza√ß√£o dos nomes das colunas\n",
        "\n",
        "Os nomes das colunas s√£o normalizados para remover acentos, espa√ßos e inconsist√™ncias de formata√ß√£o, facilitando o uso em ferramentas anal√≠ticas e evitando erros futuros.\n",
        "\n",
        "## 2.2 Convers√£o de valores monet√°rios\n",
        "\n",
        "A coluna de valores financeiros √© convertida corretamente para o tipo num√©rico, respeitando o padr√£o brasileiro de separadores decimais, garantindo precis√£o em c√°lculos e an√°lises.\n",
        "\n",
        "## 2.3 Tratamento de datas\n",
        "\n",
        "A coluna de data √© convertida para o formato de data do Python, com tratamento de valores inv√°lidos, assegurando consist√™ncia temporal no dataset.\n",
        "\n",
        "## 2.4 Convers√£o de c√≥digos num√©ricos\n",
        "\n",
        "Colunas que representam c√≥digos administrativos s√£o convertidas para o tipo inteiro, preservando valores nulos quando necess√°rio e garantindo melhor desempenho em an√°lises e relacionamentos.\n",
        "\n",
        "## 2.5 Padroniza√ß√£o de colunas de texto\n",
        "\n",
        "As colunas textuais passam por limpeza b√°sica, como remo√ß√£o de espa√ßos extras, garantindo maior qualidade dos dados.\n",
        "\n",
        "### üîç Destaque importante:\n",
        "A coluna **CodigoFavorecido** foi mantida e tratada como **texto**, pois na base original ela pode conter **valores alfanum√©ricos**. Essa decis√£o evita perda de informa√ß√£o e demonstra aten√ß√£o √† natureza real dos dados, uma pr√°tica essencial em projetos de dados profissionais.\n"
      ],
      "metadata": {
        "id": "-T3YSsHn0YkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ETAPA 2 ‚Äì TRANSFORMA√á√ÉO DOS DADOS\n",
        "# ============================================================\n",
        "\n",
        "df = pd.read_csv(\n",
        "    raw_file,\n",
        "    sep=';',\n",
        "    encoding='latin1',\n",
        "    low_memory=False\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2.1 ‚Äì Padroniza√ß√£o dos nomes das colunas\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "def normalizar_coluna(col):\n",
        "    col = col.strip()\n",
        "    col = unicodedata.normalize(\"NFKD\", col).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
        "    col = col.replace(\" \", \"\")\n",
        "    return col\n",
        "\n",
        "df.columns = [normalizar_coluna(c) for c in df.columns]\n",
        "\n",
        "if \"Anoemesdolancamento\" in df.columns:\n",
        "    df.rename(columns={\"Anoemesdolancamento\": \"DataLancamento\"}, inplace=True)\n",
        "else:\n",
        "    raise Exception(\"Coluna de data n√£o encontrada no dataset.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2.2 ‚Äì Convers√£o de valores monet√°rios\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "df[\"ValorRecebido\"] = (\n",
        "    df[\"ValorRecebido\"]\n",
        "      .astype(str)\n",
        "      .str.replace(\".\", \"\", regex=False)\n",
        "      .str.replace(\",\", \".\", regex=False)\n",
        "      .astype(float)\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2.3 ‚Äì Convers√£o da coluna de data\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "df[\"DataLancamento\"] = pd.to_datetime(\n",
        "    df[\"DataLancamento\"],\n",
        "    dayfirst=True,\n",
        "    errors=\"coerce\"\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2.4 ‚Äì Convers√£o de c√≥digos para inteiro\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "colunas_inteiro = [\n",
        "    \"CodigoOrgaoSuperior\",\n",
        "    \"CodigoOrgao\",\n",
        "    \"CodigoUnidadeGestora\"\n",
        "]\n",
        "\n",
        "for col in colunas_inteiro:\n",
        "    df[col] = (\n",
        "        df[col]\n",
        "          .astype(str)\n",
        "          .str.replace(\".0\", \"\", regex=False)\n",
        "          .replace(\"nan\", None)\n",
        "          .astype(\"Int64\")\n",
        "    )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2.5 ‚Äì Padroniza√ß√£o das colunas texto\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "colunas_texto = [\n",
        "    \"CodigoFavorecido\",\n",
        "    \"NomeFavorecido\",\n",
        "    \"SiglaUF\",\n",
        "    \"NomeMunicipio\",\n",
        "    \"NomeOrgaoSuperior\",\n",
        "    \"NomeOrgao\",\n",
        "    \"NomeUnidadeGestora\"\n",
        "]\n",
        "\n",
        "for col in colunas_texto:\n",
        "    df[col] = df[col].astype(str).str.strip()\n"
      ],
      "metadata": {
        "id": "iD5dgQCX06rE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìà Etapa 3 ‚Äì Prepara√ß√£o Final para An√°lise (Load)\n",
        "\n",
        "Na etapa final, os dados s√£o preparados para consumo no Power BI:\n",
        "\n",
        "Garantia dos tipos finais das colunas, assegurando compatibilidade com ferramentas de BI;\n",
        "\n",
        "Sele√ß√£o e ordena√ß√£o das colunas mais relevantes para an√°lise;\n",
        "\n",
        "Exporta√ß√£o do dataset final em formato CSV, com encoding adequado e separador compat√≠vel com o Power BI.\n",
        "\n",
        "O arquivo final √© salvo na pasta de dados processados, pronto para visualiza√ß√µes e an√°lises."
      ],
      "metadata": {
        "id": "W1kPiRq31Gno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ETAPA 3 ‚Äì PREPARA√á√ÉO FINAL PARA POWER BI\n",
        "# ============================================================\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3.1 ‚Äì Garantia dos tipos finais\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "df[\"DataLancamento\"] = df[\"DataLancamento\"].dt.date\n",
        "df[\"ValorRecebido\"] = df[\"ValorRecebido\"].astype(float)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3.2 ‚Äì Sele√ß√£o e ordena√ß√£o das colunas finais\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "colunas_final = [\n",
        "    \"DataLancamento\",\n",
        "    \"ValorRecebido\",\n",
        "    \"CodigoFavorecido\",\n",
        "    \"NomeFavorecido\",\n",
        "    \"SiglaUF\",\n",
        "    \"NomeMunicipio\",\n",
        "    \"CodigoOrgaoSuperior\",\n",
        "    \"NomeOrgaoSuperior\",\n",
        "    \"CodigoOrgao\",\n",
        "    \"NomeOrgao\",\n",
        "    \"CodigoUnidadeGestora\",\n",
        "    \"NomeUnidadeGestora\"\n",
        "]\n",
        "\n",
        "df = df[colunas_final]\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3.3 ‚Äì Exporta√ß√£o do dataset final\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "output_file = os.path.join(\n",
        "    PROCESSED_DIR,\n",
        "    \"despesas_favorecidos_202511_powerbi.csv\"\n",
        ")\n",
        "\n",
        "df.to_csv(\n",
        "    output_file,\n",
        "    index=False,\n",
        "    sep=';',\n",
        "    encoding='latin1'\n",
        ")\n",
        "\n",
        "print(\"üéâ Dataset final preparado para consumo no Power BI!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsU9rJey1Gz1",
        "outputId": "f5b8a967-730d-4571-ec3c-fb1599ea1f90"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéâ Dataset final preparado para consumo no Power BI!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Boas Pr√°ticas Aplicadas\n",
        "\n",
        "* Separa√ß√£o clara entre dados brutos e processados;\n",
        "\n",
        "* C√≥digo organizado por etapas do ETL;\n",
        "\n",
        "* Tratamento expl√≠cito de erros e valida√ß√µes;\n",
        "\n",
        "* Padroniza√ß√£o de nomes e tipos de dados;\n",
        "\n",
        "* Decis√µes t√©cnicas baseadas na natureza real dos dados;\n",
        "\n",
        "* Foco em reprodutibilidade, clareza e qualidade dos dados."
      ],
      "metadata": {
        "id": "Jgzj4cL71d0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéØ Conclus√£o\n",
        "\n",
        "Este projeto demonstra a aplica√ß√£o pr√°tica de um pipeline ETL completo, desde a extra√ß√£o de dados p√∫blicos at√© a entrega de um dataset pronto para an√°lise. A solu√ß√£o equilibra **qualidade t√©cnica, clareza de implementa√ß√£o e boas pr√°ticas de engenharia de dados**."
      ],
      "metadata": {
        "id": "jrR8ckbR1l9H"
      }
    }
  ]
}
